{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Phase 2: Dynamic Sign Language Word Recognition\n",
    "\n",
    " **DAEN 429 Course Project - Temporal Modeling for Video Sequences**\n",
    "\n",
    "\n",
    "\n",
    " This script implements temporal modeling for dynamic sign language word recognition using:\n",
    "\n",
    " - **Feature Extractor**: Best Phase 1 model (T-C ResNet-18) with FC removed\n",
    "\n",
    " - **Dataset**: WLASL100 (100 word classes, video clips)\n",
    "\n",
    " - **Temporal Model**: LSTM\n",
    "\n",
    " - **Training Configurations**:\n",
    "\n",
    "   - **2A**: Freeze entire CNN, train temporal head only\n",
    "\n",
    "   - **2B**: Unfreeze layer4, train layer4 + temporal head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080\n",
      "GPU Memory: 16.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 429\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'num_classes': 100, 'num_frames': 8, 'batch_size': 16, 'num_epochs': 40, 'learning_rate': 0.001, 'weight_decay': 0.0001, 'seed': 429, 'num_workers': 0, 'hidden_size': 256, 'num_lstm_layers': 1, 'dropout': 0.4}\n",
      "\n",
      "Phase 1 checkpoint: C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\checkpoints\\T-C_best.pth\n",
      "Phase 1 checkpoint exists: True\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_ROOT = Path(r\"C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\")\n",
    "WLASL_ROOT = DATA_ROOT / \"WLASL_100_frames\"  # Pre-extracted frames (10-100x faster!)\n",
    "TRAIN_DIR = WLASL_ROOT / \"train\"\n",
    "VAL_DIR = WLASL_ROOT / \"val\"\n",
    "TEST_DIR = WLASL_ROOT / \"test\"\n",
    "CHECKPOINT_DIR = DATA_ROOT / \"checkpoints\"\n",
    "FIGS_DIR = DATA_ROOT / \"figs\"  # Directory for saving figures\n",
    "FIGS_DIR.mkdir(exist_ok=True)\n",
    "PHASE1_CHECKPOINT = CHECKPOINT_DIR / \"T-C_best.pth\"  # Best Phase 1 model\n",
    "\n",
    "# Hyperparameters\n",
    "CONFIG = {\n",
    "    'num_classes': 100,  # WLASL100 has 100 word classes\n",
    "    'num_frames': 8,  # Number of frames per video (pre-extracted)\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 40,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'seed': SEED,\n",
    "    'num_workers': 0,  # Set to 0 on Windows to avoid multiprocessing issues\n",
    "    'hidden_size': 256,  # LSTM hidden size\n",
    "    'num_lstm_layers': 1,  # Number of LSTM layers\n",
    "    'dropout': 0.4,  # Dropout for regularization\n",
    "}\n",
    "\n",
    "# ImageNet normalization (required for pretrained ResNet)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "print(f\"Configuration: {CONFIG}\")\n",
    "print(f\"\\nPhase 1 checkpoint: {PHASE1_CHECKPOINT}\")\n",
    "print(f\"Phase 1 checkpoint exists: {PHASE1_CHECKPOINT.exists()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLASL100 Dataset Statistics (Pre-extracted Frames):\n",
      "=============================================================\n",
      "Number of classes: 100\n",
      "\n",
      "Classes (first 20): ['accident', 'africa', 'all', 'apple', 'basketball', 'bed', 'before', 'bird', 'birthday', 'black', 'blue', 'book', 'bowling', 'brown', 'but', 'can', 'candy', 'chair', 'change', 'cheat']\n",
      "\n",
      "Split verification:\n",
      "  Train classes: 100\n",
      "  Val classes: 100\n",
      "  Test classes: 97\n",
      "  All splits have same classes: False\n",
      "\n",
      "Video counts (as frame directories):\n",
      "  Train videos: 1001\n",
      "  Val videos: 242\n",
      "  Test videos: 200\n",
      "  Total videos: 1443\n",
      "  Avg per class: 14.4\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset structure\n",
    "def explore_wlasl_dataset(root_dir):\n",
    "    \"\"\"Explore WLASL dataset structure and statistics.\"\"\"\n",
    "    train_classes = sorted([d.name for d in (root_dir / \"train\").iterdir() if d.is_dir()])\n",
    "    val_classes = sorted([d.name for d in (root_dir / \"val\").iterdir() if d.is_dir()])\n",
    "    test_classes = sorted([d.name for d in (root_dir / \"test\").iterdir() if d.is_dir()])\n",
    "\n",
    "    print(f\"WLASL100 Dataset Statistics (Pre-extracted Frames):\")\n",
    "    print(f\"={'='*60}\")\n",
    "    print(f\"Number of classes: {len(train_classes)}\")\n",
    "    print(f\"\\nClasses (first 20): {train_classes[:20]}\")\n",
    "    print(f\"\\nSplit verification:\")\n",
    "    print(f\"  Train classes: {len(train_classes)}\")\n",
    "    print(f\"  Val classes: {len(val_classes)}\")\n",
    "    print(f\"  Test classes: {len(test_classes)}\")\n",
    "    print(f\"  All splits have same classes: {train_classes == val_classes == test_classes}\")\n",
    "\n",
    "    # Count frame directories (each directory = one video's frames)\n",
    "    train_videos = sum([len(list((root_dir / \"train\" / c).iterdir()))\n",
    "                        for c in train_classes if (root_dir / \"train\" / c).is_dir()])\n",
    "    val_videos = sum([len(list((root_dir / \"val\" / c).iterdir()))\n",
    "                      for c in val_classes if (root_dir / \"val\" / c).is_dir()])\n",
    "    test_videos = sum([len(list((root_dir / \"test\" / c).iterdir()))\n",
    "                       for c in test_classes if (root_dir / \"test\" / c).is_dir()])\n",
    "\n",
    "    print(f\"\\nVideo counts (as frame directories):\")\n",
    "    print(f\"  Train videos: {train_videos}\")\n",
    "    print(f\"  Val videos: {val_videos}\")\n",
    "    print(f\"  Test videos: {test_videos}\")\n",
    "    print(f\"  Total videos: {train_videos + val_videos + test_videos}\")\n",
    "    print(f\"  Avg per class: {(train_videos + val_videos + test_videos) / len(train_classes):.1f}\")\n",
    "    print(f\"={'='*60}\")\n",
    "\n",
    "    return train_classes\n",
    "\n",
    "class_names = explore_wlasl_dataset(WLASL_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Video Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WLASL_FramesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    WLASL Frames Dataset for sign language word recognition.\n",
    "    \n",
    "    Loads pre-extracted frames from disk (MUCH faster than video loading!).\n",
    "    Frames are stored as: WLASL_100_frames/split/class/video_id/frame_00.jpg\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, num_frames=8, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Root directory containing frames (train/val/test)\n",
    "            num_frames: Number of frames per video (should match preprocessing)\n",
    "            transform: Transforms to apply to each frame\n",
    "        \"\"\"\n",
    "        from PIL import Image\n",
    "        self.PIL_Image = Image  # Store for later use\n",
    "        \n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.num_frames = num_frames\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Build dataset\n",
    "        self.samples = []  # List of (video_frames_dir, class_idx)\n",
    "        self.classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.root_dir / class_name\n",
    "            class_idx = self.class_to_idx[class_name]\n",
    "            \n",
    "            # Each subdirectory contains frames for one video\n",
    "            for video_dir in class_dir.iterdir():\n",
    "                if video_dir.is_dir():\n",
    "                    self.samples.append((str(video_dir), class_idx))\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} videos (as pre-extracted frames) from {root_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        video_frames_dir, label = self.samples[idx]\n",
    "        video_frames_path = Path(video_frames_dir)\n",
    "        \n",
    "        # Load all frames from the directory\n",
    "        frames = []\n",
    "        for i in range(self.num_frames):\n",
    "            frame_path = video_frames_path / f\"frame_{i:02d}.jpg\"\n",
    "            if frame_path.exists():\n",
    "                frame = self.PIL_Image.open(frame_path).convert('RGB')\n",
    "                frames.append(frame)\n",
    "            else:\n",
    "                # If frame doesn't exist, duplicate the last frame\n",
    "                if frames:\n",
    "                    frames.append(frames[-1])\n",
    "                else:\n",
    "                    raise ValueError(f\"No frames found in {video_frames_dir}\")\n",
    "        \n",
    "        # Apply transform to each frame\n",
    "        if self.transform:\n",
    "            frames = torch.stack([self.transform(frame) for frame in frames])\n",
    "        else:\n",
    "            # Convert to tensor if no transform\n",
    "            import torchvision.transforms as T\n",
    "            to_tensor = T.ToTensor()\n",
    "            frames = torch.stack([to_tensor(frame) for frame in frames])\n",
    "        \n",
    "        return frames, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 5. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets from pre-extracted frames...\n",
      "Loaded 1001 videos (as pre-extracted frames) from C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\WLASL_100_frames\\train\n",
      "Loaded 242 videos (as pre-extracted frames) from C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\WLASL_100_frames\\val\n",
      "Loaded 200 videos (as pre-extracted frames) from C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\WLASL_100_frames\\test\n",
      "\n",
      "DataLoader info:\n",
      "  Train batches: 63\n",
      "  Val batches: 16\n",
      "  Test batches: 13\n"
     ]
    }
   ],
   "source": [
    "# Define transforms for video frames (same as Phase 1)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Create datasets (using pre-extracted frames for speed!)\n",
    "print(\"Creating datasets from pre-extracted frames...\")\n",
    "train_dataset = WLASL_FramesDataset(TRAIN_DIR, num_frames=CONFIG['num_frames'], transform=train_transform)\n",
    "val_dataset = WLASL_FramesDataset(VAL_DIR, num_frames=CONFIG['num_frames'], transform=val_transform)\n",
    "test_dataset = WLASL_FramesDataset(TEST_DIR, num_frames=CONFIG['num_frames'], transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoader info:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 6. Load Phase 1 Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Phase 1 checkpoint from C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\checkpoints\\T-C_best.pth...\n",
      "✓ Phase 1 weights loaded successfully\n",
      "✓ Feature extractor frozen\n",
      "\n",
      "Feature extractor output shape: (batch, 512)\n"
     ]
    }
   ],
   "source": [
    "def create_feature_extractor_from_phase1(checkpoint_path, freeze=True):\n",
    "    \"\"\"\n",
    "    Load Phase 1's best ResNet-18 model and convert to feature extractor.\n",
    "    \n",
    "    Removes the FC layer and adds global average pooling.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to Phase 1 checkpoint (T-C_best.pth)\n",
    "        freeze: Whether to freeze all CNN parameters\n",
    "    \n",
    "    Returns:\n",
    "        feature_extractor: ResNet-18 without FC layer (outputs 512-dim features)\n",
    "    \"\"\"\n",
    "    # Load pretrained ResNet-18 architecture\n",
    "    resnet = models.resnet18(weights=None)\n",
    "    \n",
    "    # Modify FC to match Phase 1 (29 classes)\n",
    "    resnet.fc = nn.Linear(resnet.fc.in_features, 29)\n",
    "    \n",
    "    # Load Phase 1 trained weights\n",
    "    print(f\"Loading Phase 1 checkpoint from {checkpoint_path}...\")\n",
    "    state_dict = torch.load(checkpoint_path, map_location='cpu')\n",
    "    resnet.load_state_dict(state_dict)\n",
    "    print(\"✓ Phase 1 weights loaded successfully\")\n",
    "    \n",
    "    # Remove FC layer and create feature extractor\n",
    "    feature_extractor = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC layer\n",
    "    # Output is (batch, 512, 1, 1) after avgpool, we'll flatten to (batch, 512)\n",
    "    \n",
    "    if freeze:\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        feature_extractor.eval()\n",
    "        print(\"✓ Feature extractor frozen\")\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "# Load feature extractor\n",
    "cnn_feature_extractor = create_feature_extractor_from_phase1(PHASE1_CHECKPOINT, freeze=True)\n",
    "print(f\"\\nFeature extractor output shape: (batch, 512)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 7. Temporal Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture:\n",
      "TemporalSignLanguageModel(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (lstm): LSTM(512, 256, batch_first=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.4, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=100, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 11,990,692\n",
      "Trainable parameters: 814,180 (6.79%)\n"
     ]
    }
   ],
   "source": [
    "class TemporalSignLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete model for temporal sign language recognition.\n",
    "    \n",
    "    Architecture:\n",
    "        CNN Feature Extractor (per frame) → LSTM (temporal) → Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, cnn_feature_extractor, num_classes=100, \n",
    "                 hidden_size=512, num_layers=2, dropout=0.3):\n",
    "        super(TemporalSignLanguageModel, self).__init__()\n",
    "        \n",
    "        self.cnn = cnn_feature_extractor\n",
    "        self.feature_dim = 512  # ResNet-18 feature dimension\n",
    "        \n",
    "        # LSTM for temporal modeling\n",
    "        # Note: LSTM dropout only applies when num_layers > 1\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.feature_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,  # No dropout for single layer\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: Video tensor (batch, num_frames, C, H, W)\n",
    "        \n",
    "        Returns:\n",
    "            logits: (batch, num_classes)\n",
    "        \"\"\"\n",
    "        batch_size, num_frames, C, H, W = x.shape\n",
    "        \n",
    "        # Extract features for each frame\n",
    "        # Reshape to (batch * num_frames, C, H, W)\n",
    "        x = x.view(batch_size * num_frames, C, H, W)\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        with torch.set_grad_enabled(self.cnn.training):\n",
    "            features = self.cnn(x)  # (batch * num_frames, 512, 1, 1)\n",
    "        \n",
    "        # Flatten and reshape to (batch, num_frames, 512)\n",
    "        features = features.view(batch_size, num_frames, -1)\n",
    "        \n",
    "        # LSTM temporal modeling\n",
    "        lstm_out, (hidden, cell) = self.lstm(features)\n",
    "        \n",
    "        # Use the last hidden state for classification\n",
    "        final_hidden = lstm_out[:, -1, :]  # (batch, hidden_size)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(final_hidden)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Test model creation\n",
    "test_model = TemporalSignLanguageModel(\n",
    "    cnn_feature_extractor,\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    num_layers=CONFIG['num_lstm_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(test_model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in test_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in test_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "\n",
    "del test_model  # Clean up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 8. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model):\n",
    "    \"\"\"Freeze all parameters.\"\"\"\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_cnn_layer4(model):\n",
    "    \"\"\"\n",
    "    Unfreeze layer4 of the CNN feature extractor.\n",
    "    Assumes model.cnn is a Sequential of ResNet layers.\n",
    "    \"\"\"\n",
    "    # model.cnn is nn.Sequential(*resnet.children()[:-1])\n",
    "    # We need to access layer4 which is in the sequence\n",
    "    for name, module in model.cnn.named_modules():\n",
    "        if 'layer4' in name or name == '7':  # layer4 is typically index 7 in children\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total and trainable parameters.\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device, clip_grad=1.0):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for videos, labels in tqdm(loader, desc='Training', leave=False):\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        if clip_grad > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * videos.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for videos, labels in tqdm(loader, desc='Evaluating', leave=False):\n",
    "            videos, labels = videos.to(device), labels.to(device)\n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * videos.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(all_labels)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return epoch_loss, accuracy * 100, macro_f1, all_preds, all_labels\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
    "                num_epochs, device, model_name, save_best=True, use_scheduler=True):\n",
    "    \"\"\"\n",
    "    Complete training loop with validation.\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Add learning rate scheduler\n",
    "    if use_scheduler:\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=5\n",
    "        )\n",
    "\n",
    "    best_val_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train with gradient clipping\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, clip_grad=1.0)\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        # Record history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Save best model\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch\n",
    "            if save_best:\n",
    "                torch.save(best_model_state, CHECKPOINT_DIR / f\"{model_name}_best.pth\")\n",
    "\n",
    "        # Step scheduler\n",
    "        if use_scheduler:\n",
    "            scheduler.step(val_f1)\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] ({epoch_time:.1f}s) | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}\")\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Best validation F1: {best_val_f1:.4f} at epoch {best_epoch+1}\")\n",
    "    print(f\"Best model saved to: {CHECKPOINT_DIR / f'{model_name}_best.pth'}\\n\")\n",
    "\n",
    "    return history, best_model_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 9. Configuration 2A: Frozen CNN, Train Temporal Head Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONFIGURATION 2A: FROZEN CNN + TEMPORAL HEAD\n",
      "================================================================================\n",
      "Freeze: Entire CNN (all ResNet layers)\n",
      "Train: LSTM + Classifier head\n",
      "================================================================================\n",
      "Loading Phase 1 checkpoint from C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\checkpoints\\T-C_best.pth...\n",
      "✓ Phase 1 weights loaded successfully\n",
      "✓ Feature extractor frozen\n",
      "\n",
      "Total parameters: 11,990,692\n",
      "Trainable parameters: 814,180 (6.79%)\n",
      "\n",
      "Training 2A...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] (56.5s) | Train Loss: 4.6471, Acc: 0.90% | Val Loss: 4.6058, Acc: 0.83%, F1: 0.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40] (50.6s) | Train Loss: 4.6055, Acc: 1.50% | Val Loss: 4.6042, Acc: 2.07%, F1: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40] (51.8s) | Train Loss: 4.5700, Acc: 2.50% | Val Loss: 4.5993, Acc: 2.07%, F1: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40] (47.9s) | Train Loss: 4.5226, Acc: 3.00% | Val Loss: 4.6237, Acc: 1.65%, F1: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40] (48.1s) | Train Loss: 4.4743, Acc: 3.90% | Val Loss: 4.5782, Acc: 1.24%, F1: 0.0022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40] (53.0s) | Train Loss: 4.4505, Acc: 4.40% | Val Loss: 4.6029, Acc: 1.65%, F1: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40] (51.3s) | Train Loss: 4.3905, Acc: 4.80% | Val Loss: 4.5790, Acc: 2.89%, F1: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40] (50.1s) | Train Loss: 4.3388, Acc: 4.50% | Val Loss: 4.6205, Acc: 1.65%, F1: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40] (50.2s) | Train Loss: 4.2874, Acc: 6.09% | Val Loss: 4.5899, Acc: 2.48%, F1: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40] (51.8s) | Train Loss: 4.2294, Acc: 6.39% | Val Loss: 4.6052, Acc: 2.48%, F1: 0.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/40] (51.7s) | Train Loss: 4.1890, Acc: 7.19% | Val Loss: 4.5931, Acc: 3.31%, F1: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40] (54.4s) | Train Loss: 4.1565, Acc: 8.29% | Val Loss: 4.5907, Acc: 2.07%, F1: 0.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40] (53.6s) | Train Loss: 4.0795, Acc: 8.09% | Val Loss: 4.6095, Acc: 2.48%, F1: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40] (51.5s) | Train Loss: 4.0527, Acc: 9.19% | Val Loss: 4.5603, Acc: 3.72%, F1: 0.0267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40] (51.2s) | Train Loss: 3.9783, Acc: 11.09% | Val Loss: 4.5975, Acc: 1.65%, F1: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40] (51.1s) | Train Loss: 3.9570, Acc: 11.69% | Val Loss: 4.5836, Acc: 3.31%, F1: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40] (52.3s) | Train Loss: 3.9139, Acc: 10.69% | Val Loss: 4.6032, Acc: 4.96%, F1: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40] (53.1s) | Train Loss: 3.8477, Acc: 11.99% | Val Loss: 4.5769, Acc: 4.13%, F1: 0.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40] (52.1s) | Train Loss: 3.7955, Acc: 13.09% | Val Loss: 4.5435, Acc: 4.13%, F1: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40] (52.7s) | Train Loss: 3.7629, Acc: 13.19% | Val Loss: 4.5391, Acc: 4.96%, F1: 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/40] (55.3s) | Train Loss: 3.7227, Acc: 13.79% | Val Loss: 4.5487, Acc: 5.79%, F1: 0.0461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/40] (52.9s) | Train Loss: 3.6848, Acc: 14.99% | Val Loss: 4.5227, Acc: 7.85%, F1: 0.0588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/40] (50.2s) | Train Loss: 3.6379, Acc: 17.08% | Val Loss: 4.5401, Acc: 5.37%, F1: 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/40] (52.7s) | Train Loss: 3.5992, Acc: 17.78% | Val Loss: 4.5628, Acc: 5.37%, F1: 0.0404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/40] (56.1s) | Train Loss: 3.5640, Acc: 18.28% | Val Loss: 4.5449, Acc: 7.02%, F1: 0.0532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/40] (54.6s) | Train Loss: 3.5194, Acc: 18.58% | Val Loss: 4.5542, Acc: 5.37%, F1: 0.0446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/40] (52.8s) | Train Loss: 3.4572, Acc: 21.58% | Val Loss: 4.5629, Acc: 7.85%, F1: 0.0584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/40] (52.1s) | Train Loss: 3.4240, Acc: 21.88% | Val Loss: 4.5463, Acc: 7.02%, F1: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/40] (52.2s) | Train Loss: 3.2574, Acc: 23.98% | Val Loss: 4.5409, Acc: 9.50%, F1: 0.0814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/40] (55.2s) | Train Loss: 3.2153, Acc: 26.77% | Val Loss: 4.5281, Acc: 10.74%, F1: 0.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/40] (55.6s) | Train Loss: 3.2062, Acc: 27.47% | Val Loss: 4.5425, Acc: 9.92%, F1: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/40] (51.3s) | Train Loss: 3.1522, Acc: 26.97% | Val Loss: 4.5462, Acc: 9.92%, F1: 0.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/40] (54.4s) | Train Loss: 3.1414, Acc: 28.87% | Val Loss: 4.5799, Acc: 9.50%, F1: 0.0823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/40] (57.2s) | Train Loss: 3.0841, Acc: 30.87% | Val Loss: 4.5638, Acc: 10.33%, F1: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/40] (52.8s) | Train Loss: 3.0831, Acc: 29.97% | Val Loss: 4.4915, Acc: 10.33%, F1: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/40] (52.5s) | Train Loss: 3.0051, Acc: 31.17% | Val Loss: 4.5351, Acc: 10.74%, F1: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/40] (52.0s) | Train Loss: 3.0001, Acc: 32.07% | Val Loss: 4.5389, Acc: 10.33%, F1: 0.0856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/40] (53.0s) | Train Loss: 2.9192, Acc: 33.27% | Val Loss: 4.5429, Acc: 11.16%, F1: 0.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/40] (59.3s) | Train Loss: 2.9074, Acc: 35.66% | Val Loss: 4.5611, Acc: 11.16%, F1: 0.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/40] (58.8s) | Train Loss: 2.8581, Acc: 36.56% | Val Loss: 4.5337, Acc: 13.64%, F1: 0.1103\n",
      "======================================================================\n",
      "Best validation F1: 0.1103 at epoch 40\n",
      "Best model saved to: C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\checkpoints\\2A_best.pth\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIGURATION 2A: FROZEN CNN + TEMPORAL HEAD\")\n",
    "print(\"=\"*80)\n",
    "print(\"Freeze: Entire CNN (all ResNet layers)\")\n",
    "print(\"Train: LSTM + Classifier head\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create feature extractor (frozen)\n",
    "cnn_2a = create_feature_extractor_from_phase1(PHASE1_CHECKPOINT, freeze=True)\n",
    "\n",
    "# Create model\n",
    "model_2a = TemporalSignLanguageModel(\n",
    "    cnn_2a,\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    num_layers=CONFIG['num_lstm_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "model_2a = model_2a.to(device)\n",
    "\n",
    "# Print trainable parameters\n",
    "total, trainable = count_parameters(model_2a)\n",
    "print(f\"\\nTotal parameters: {total:,}\")\n",
    "print(f\"Trainable parameters: {trainable:,} ({100*trainable/total:.2f}%)\")\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_2a = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_2a.parameters()),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Train\n",
    "history_2a, best_model_2a = train_model(\n",
    "    model_2a, train_loader, val_loader, criterion, optimizer_2a,\n",
    "    num_epochs=CONFIG['num_epochs'], device=device, model_name='2A', use_scheduler=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 10. Configuration 2B: Unfreeze Layer4, Train Layer4 + Temporal Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONFIGURATION 2B: UNFREEZE LAYER4 + TEMPORAL HEAD\n",
      "================================================================================\n",
      "Freeze: CNN stem + layer1 + layer2 + layer3\n",
      "Train: layer4 + LSTM + Classifier head\n",
      "================================================================================\n",
      "Loading Phase 1 checkpoint from C:\\Users\\robin\\OneDrive\\Documents\\code\\daen429-project\\checkpoints\\T-C_best.pth...\n",
      "✓ Phase 1 weights loaded successfully\n",
      "✓ Feature extractor frozen\n",
      "\n",
      "Total parameters: 11,990,692\n",
      "Trainable parameters: 9,207,908 (76.79%)\n",
      "\n",
      "Training 2B...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 41/63 [00:29<00:15,  1.43it/s]"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFIGURATION 2B: UNFREEZE LAYER4 + TEMPORAL HEAD\")\n",
    "print(\"=\"*80)\n",
    "print(\"Freeze: CNN stem + layer1 + layer2 + layer3\")\n",
    "print(\"Train: layer4 + LSTM + Classifier head\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create feature extractor (initially frozen)\n",
    "cnn_2b = create_feature_extractor_from_phase1(PHASE1_CHECKPOINT, freeze=True)\n",
    "\n",
    "# Create model\n",
    "model_2b = TemporalSignLanguageModel(\n",
    "    cnn_2b,\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    hidden_size=CONFIG['hidden_size'],\n",
    "    num_layers=CONFIG['num_lstm_layers'],\n",
    "    dropout=CONFIG['dropout']\n",
    ")\n",
    "\n",
    "# Unfreeze layer4\n",
    "unfreeze_cnn_layer4(model_2b)\n",
    "model_2b = model_2b.to(device)\n",
    "\n",
    "# Print trainable parameters\n",
    "total, trainable = count_parameters(model_2b)\n",
    "print(f\"\\nTotal parameters: {total:,}\")\n",
    "print(f\"Trainable parameters: {trainable:,} ({100*trainable/total:.2f}%)\")\n",
    "\n",
    "# Setup training with lower learning rate\n",
    "optimizer_2b = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_2b.parameters()),\n",
    "    lr=CONFIG['learning_rate'] * 0.5,  # Lower LR for fine-tuning\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Train\n",
    "history_2b, best_model_2b = train_model(\n",
    "    model_2b, train_loader, val_loader, criterion, optimizer_2b,\n",
    "    num_epochs=CONFIG['num_epochs'], device=device, model_name='2B', use_scheduler=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 11. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VALIDATION SET RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect histories\n",
    "all_histories = [history_2a, history_2b]\n",
    "model_names = ['2A (Frozen CNN)', '2B (Layer4 Unfrozen)']\n",
    "\n",
    "# Create comparison table\n",
    "results_summary = []\n",
    "for history, name in zip(all_histories, model_names):\n",
    "    best_f1 = max(history['val_f1'])\n",
    "    best_f1_epoch = history['val_f1'].index(best_f1) + 1\n",
    "    best_acc = history['val_acc'][best_f1_epoch - 1]\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Model': name,\n",
    "        'Best Val F1': best_f1,\n",
    "        'Best Val Acc (%)': best_acc,\n",
    "        'Epoch': best_f1_epoch\n",
    "    })\n",
    "\n",
    "# Print results\n",
    "print(f\"\\n{'Model':<25} {'Best Val F1':>12} {'Best Val Acc (%)':>16} {'Epoch':>8}\")\n",
    "print(\"-\" * 70)\n",
    "for result in results_summary:\n",
    "    print(f\"{result['Model']:<25} {result['Best Val F1']:>12.4f} \"\n",
    "          f\"{result['Best Val Acc (%)']:>16.2f} {result['Epoch']:>8}\")\n",
    "\n",
    "# Find best model\n",
    "best_idx = np.argmax([r['Best Val F1'] for r in results_summary])\n",
    "best_model_name = results_summary[best_idx]['Model']\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"Best Validation F1: {results_summary[best_idx]['Best Val F1']:.4f}\")\n",
    "print(f\"Best Validation Accuracy: {results_summary[best_idx]['Best Val Acc (%)']:.2f}%\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 12. Visualize Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Phase 2: Training and Validation Curves', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "ax = axes[0, 0]\n",
    "for history, name in zip(all_histories, model_names):\n",
    "    ax.plot(history['train_loss'], label=name, linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Validation Loss\n",
    "ax = axes[0, 1]\n",
    "for history, name in zip(all_histories, model_names):\n",
    "    ax.plot(history['val_loss'], label=name, linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Validation Loss')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Training Accuracy\n",
    "ax = axes[1, 0]\n",
    "for history, name in zip(all_histories, model_names):\n",
    "    ax.plot(history['train_acc'], label=name, linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('Training Accuracy')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Validation F1\n",
    "ax = axes[1, 1]\n",
    "for history, name in zip(all_histories, model_names):\n",
    "    ax.plot(history['val_f1'], label=name, linewidth=2, marker='o', markersize=3)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Macro-F1')\n",
    "ax.set_title('Validation Macro-F1')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGS_DIR / 'phase2_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 13. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TEST SET EVALUATION - {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load best model\n",
    "best_models = [(model_2a, best_model_2a, '2A'), (model_2b, best_model_2b, '2B')]\n",
    "selected_model, selected_weights, selected_name = best_models[best_idx]\n",
    "selected_model.load_state_dict(selected_weights)\n",
    "selected_model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    selected_model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"  Macro-F1: {test_f1:.4f}\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=class_names, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 14. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(20, 18))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title(f'Confusion Matrix - {best_model_name} (Test Set)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xticks(rotation=90, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGS_DIR / f'phase2_confusion_matrix_{selected_name}_test.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 15. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PHASE 2 EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"1. Best performing model: {best_model_name}\")\n",
    "print(f\"2. Best validation F1 score: {results_summary[best_idx]['Best Val F1']:.4f}\")\n",
    "print(f\"3. Test set accuracy: {test_acc:.2f}%\")\n",
    "print(f\"4. Test set F1 score: {test_f1:.4f}\")\n",
    "print(\"\\nComparison:\")\n",
    "for result in results_summary:\n",
    "    print(f\"  - {result['Model']}: F1={result['Best Val F1']:.4f}, Acc={result['Best Val Acc (%)']:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Files saved:\")\n",
    "print(f\"  - Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  - Figures: {FIGS_DIR}\")\n",
    "print(f\"    - phase2_training_curves.png\")\n",
    "print(f\"    - phase2_confusion_matrix_{selected_name}_test.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
